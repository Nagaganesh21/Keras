{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop a Neural Language Model for Text Generation\n",
    "\n",
    "Try to develop a language model that can predict the probability of the next word in the sequence, based on the\n",
    "words already observed in the sequence.  For this task will use the book *The Prince by Nicoló Machiavelli*\n",
    "- http://www.gutenberg.org/ebooks/57037\n",
    "\n",
    "- http://www.gutenberg.org/cache/epub/731/pg731.txt\n",
    "\n",
    "- http://www.gutenberg.org/cache/epub/1497/pg1497.txt\n",
    "\n",
    "\n",
    "Aim is to learn:\n",
    "- How to prepare text for developing a word-based language model.\n",
    "- How to design and fit a neural language model with a learned embedding and an LSTM\n",
    "hidden layer.\n",
    "- How to use the learned language model to generate new text with similar statistical\n",
    "properties as the source text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array,iinfo\n",
    "from pickle import dump\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "from sys import getsizeof\n",
    "import time\n",
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import os\n",
    "from IPython.display import Image\n",
    "os.environ[\"PATH\"] += os.pathsep +  'C:\\\\Users/richard\\\\Anaconda3\\\\pkgs\\\\graphviz-2.38-hfd603c8_2\\\\Library\\\\bin\\\\graphviz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    file = open(filename,'r')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï»¿NICCOLÃ’ MACHIAVELLI TO LORENZO THE MAGNIFICENT\n",
      "\n",
      "1. The various kinds of Government and the ways by which they are\n",
      "established.\n",
      "\n",
      "2. Of Hereditary Monarchies.\n",
      "\n",
      "3. Of Mixed Monarchies.\n",
      "\n",
      "4. Why the Kingdom of Darius, occupied by Alexander, did not rebel\n",
      "against the successors of the latter after his death.\n",
      "\n",
      "5. The way to govern Cities or Dominions that, previous to being\n",
      "occupied, lived under thei\n"
     ]
    }
   ],
   "source": [
    "filename = 'the_prince.txt'\n",
    "doc = load_doc(filename)\n",
    "print(doc[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the text\n",
    "Clean up the text and reduce vocab size\n",
    " - remove non-printable chars\n",
    " - replace '-' with whitespace so split words better\n",
    " - remove punctuation eg. 'Who?' becomes 'Who'\n",
    " - remove non alphabetic\n",
    " - lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_doc(doc):\n",
    "    doc = doc.replace('-',' ')\n",
    "    tokens = doc.split()\n",
    "    re_punc = re.compile('[%s]' % re.escape(string.punctuation))\n",
    "    tokens = [re_punc.sub('',w) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['machiavelli', 'to', 'lorenzo', 'the', 'magnificent', 'the', 'various', 'kinds', 'of', 'government', 'and', 'the', 'ways', 'by', 'which', 'they', 'are', 'established', 'of', 'hereditary', 'monarchies', 'of', 'mixed', 'monarchies', 'why', 'the', 'kingdom', 'of', 'darius', 'occupied', 'by', 'alexander', 'did', 'not', 'rebel', 'against', 'the', 'successors', 'of', 'the', 'latter', 'after', 'his', 'death', 'the', 'way', 'to', 'govern', 'cities', 'or', 'dominions', 'that', 'previous', 'to', 'being', 'occupied', 'lived', 'under', 'their', 'own', 'laws', 'of', 'new', 'dominions', 'which', 'have', 'been', 'acquired', 'by', 'ones', 'own', 'arms', 'and', 'powers', 'of', 'new', 'dominions', 'acquired', 'by', 'the', 'power', 'of', 'others', 'or', 'by', 'fortune', 'of', 'those', 'who', 'have', 'attained', 'the', 'position', 'of', 'prince', 'by', 'villainy', 'of', 'the', 'civic', 'principality', 'how', 'the', 'strength', 'of', 'all', 'states', 'should', 'be', 'measured', 'of', 'ecclesiastical', 'principalities', 'the', 'different', 'kinds', 'of', 'militia', 'and', 'mercenary', 'soldiers', 'of', 'auxiliary', 'mixed', 'and', 'native', 'troops', 'what', 'the', 'duties', 'of', 'a', 'prince', 'are', 'with', 'regard', 'to', 'the', 'militia', 'of', 'the', 'things', 'for', 'which', 'men', 'and', 'especially', 'princes', 'are', 'praised', 'or', 'blamed', 'of', 'liberality', 'and', 'niggardliness', 'of', 'cruelty', 'and', 'clemency', 'and', 'whether', 'it', 'is', 'better', 'to', 'be', 'loved', 'or', 'feared', 'in', 'what', 'way', 'princes', 'must', 'keep', 'faith', 'that', 'we', 'must', 'avoid', 'being', 'despised', 'and', 'hated', 'whether', 'fortresses', 'and', 'other', 'things', 'which', 'princes', 'often', 'make', 'are', 'useful', 'or', 'injurious', 'how', 'a', 'prince', 'must', 'act', 'in', 'order', 'to', 'gain', 'reputation', 'of', 'the', 'secretaries', 'of', 'princes', 'how', 'flatterers', 'must', 'be', 'shunned', 'why', 'the', 'princes', 'of', 'italy', 'have', 'lost', 'their', 'states', 'how', 'much', 'fortune', 'can', 'do', 'in', 'human', 'affairs', 'and', 'how', 'it', 'may', 'be', 'opposed', 'exhortation', 'to', 'liberate', 'italy', 'from', 'the', 'barbarians', 'machiavelli', 'to', 'lorenzo', 'the', 'magnificent', 'son', 'of', 'piero', 'di', 'medici', 'it', 'is', 'customary', 'for', 'those', 'who', 'wish', 'to', 'gain', 'the', 'favour', 'of', 'a', 'prince', 'to', 'endeavour', 'to', 'do', 'so', 'by', 'offering', 'him', 'gifts', 'of', 'those', 'things', 'which', 'they', 'hold', 'most', 'precious', 'or', 'in', 'which', 'they', 'know', 'him', 'to', 'take', 'especial', 'delight', 'in']\n",
      "Total Tokens: 30581\n",
      "Unique Tokens: 3233\n"
     ]
    }
   ],
   "source": [
    "# clean document\n",
    "tokens = clean_doc(doc)\n",
    "print(tokens[:300])\n",
    "print('Total Tokens: %d' % len(tokens))\n",
    "print('Unique Tokens: %d' % len(set(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Clean Text\n",
    "Generate a sequence of tokens using 50 input words and 1 output word.  use a sliding window of length 51 across the tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 30530\n"
     ]
    }
   ],
   "source": [
    "length = 50+1\n",
    "sequences = list()\n",
    "for i in range(length,len(tokens)):   #0-51,1-52,2-53\n",
    "    seq = tokens[i-length:i]\n",
    "    line = ' '.join(seq)\n",
    "    sequences.append(line)\n",
    "    #print(sequences)\n",
    "    #break\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now have a long list of sequences, save to file for later processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tokens to file, one dialog per line\n",
    "def save_doc(lines, filename):\n",
    "    data = '\\n'.join(lines)\n",
    "    file = open(filename, 'w')\n",
    "    file.write(data)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save sequences to file\n",
    "out_filename = 'the_prince_sequences.txt'\n",
    "save_doc(sequences, out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machiavelli to lorenzo the magnificent the various kinds of government and the ways by which they are established of hereditary monarchies of mixed monarchies why the kingdom of darius occupied by alexander did not rebel against the successors of the latter after his death the way to govern cities or dominions\n",
      "to lorenzo the magnificent the various kinds of government and the ways by which they ar\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "file = open('the_prince_sequences.txt','r')\n",
    "text = file.read()\n",
    "file.close()\n",
    "print(text[:400])\n",
    "print(type(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_filename = 'the_prince_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word embedding layer expects input sequences to be comprised of integers. We can map each word in our vocabulary to a unique integer and encode our input sequences. Later, when we make predictions, we can convert the prediction to numbers and look up their associated words in the same mapping. To do this encoding, we will use the Tokenizer class in the Keras API.\n",
    "\n",
    "First, the Tokenizer must be trained on the entire training dataset, which means it finds all of the unique words in the data and assigns each a unique integer. We can then use the fit Tokenizer to encode all of the training sequences, converting each sequence from a list of words\n",
    "to a list of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "sequences = tokenizer.texts_to_sequences(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1744, 3, 1743, 1, 1742, 1, 786, 466, 4, 239, 2, 1, 238, 10, 23, 17, 24, 306, 4, 365, 579, 4, 517, 579, 936, 1, 141, 4, 784, 413, 10, 120, 92, 11, 935, 69, 1, 934, 4, 1, 305, 129, 12, 167, 1, 111, 3, 933, 364, 31, 212]]\n"
     ]
    }
   ],
   "source": [
    "#print(dir(tokenizer))\n",
    "print(sequences[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3234\n"
     ]
    }
   ],
   "source": [
    "#Access the mapping of words to integers as a dictionary attribute called word index\n",
    "#on the Tokenizer object. We need to know the size of the vocabulary for defining the embedding\n",
    "#layer later\n",
    "#find out size of vocab\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence Inputs and Output\n",
    "- extract input and output, then one hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30530, 51)\n",
      "(30530, 50)\n",
      "(30530,)\n"
     ]
    }
   ],
   "source": [
    "#numpy array\n",
    "sequences = array(sequences)\n",
    "print(sequences.shape)\n",
    "X = sequences[:,:-1]\n",
    "print(X.shape)\n",
    "y = sequences[:,-1]\n",
    "print(y.shape)\n",
    "y = to_categorical(y,num_classes=vocab_size)\n",
    "seq_length = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising the datatypes\n",
    "Values in the arrays are quite small, we can optimise these values to reduce the size of the arrays using pandas.  This should reduce the training time of the deep learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(X)\n",
    "df2 = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30530 entries, 0 to 30529\n",
      "Data columns (total 50 columns):\n",
      "0     30530 non-null int32\n",
      "1     30530 non-null int32\n",
      "2     30530 non-null int32\n",
      "3     30530 non-null int32\n",
      "4     30530 non-null int32\n",
      "5     30530 non-null int32\n",
      "6     30530 non-null int32\n",
      "7     30530 non-null int32\n",
      "8     30530 non-null int32\n",
      "9     30530 non-null int32\n",
      "10    30530 non-null int32\n",
      "11    30530 non-null int32\n",
      "12    30530 non-null int32\n",
      "13    30530 non-null int32\n",
      "14    30530 non-null int32\n",
      "15    30530 non-null int32\n",
      "16    30530 non-null int32\n",
      "17    30530 non-null int32\n",
      "18    30530 non-null int32\n",
      "19    30530 non-null int32\n",
      "20    30530 non-null int32\n",
      "21    30530 non-null int32\n",
      "22    30530 non-null int32\n",
      "23    30530 non-null int32\n",
      "24    30530 non-null int32\n",
      "25    30530 non-null int32\n",
      "26    30530 non-null int32\n",
      "27    30530 non-null int32\n",
      "28    30530 non-null int32\n",
      "29    30530 non-null int32\n",
      "30    30530 non-null int32\n",
      "31    30530 non-null int32\n",
      "32    30530 non-null int32\n",
      "33    30530 non-null int32\n",
      "34    30530 non-null int32\n",
      "35    30530 non-null int32\n",
      "36    30530 non-null int32\n",
      "37    30530 non-null int32\n",
      "38    30530 non-null int32\n",
      "39    30530 non-null int32\n",
      "40    30530 non-null int32\n",
      "41    30530 non-null int32\n",
      "42    30530 non-null int32\n",
      "43    30530 non-null int32\n",
      "44    30530 non-null int32\n",
      "45    30530 non-null int32\n",
      "46    30530 non-null int32\n",
      "47    30530 non-null int32\n",
      "48    30530 non-null int32\n",
      "49    30530 non-null int32\n",
      "dtypes: int32(50)\n",
      "memory usage: 5.8 MB\n",
      "None\n",
      " \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30530 entries, 0 to 30529\n",
      "Columns: 3234 entries, 0 to 3233\n",
      "dtypes: float64(3234)\n",
      "memory usage: 753.3 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#get the info on the data\n",
    "print(df1.info())\n",
    "print(\" \")\n",
    "print(df2.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can see that we have int32 datatypes, and float 64 for 0/1 values - do we actually need these ranges?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine parameters for uint16\n",
      "---------------------------------------------------------------\n",
      "min = 0\n",
      "max = 65535\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Machine parameters for int16\n",
      "---------------------------------------------------------------\n",
      "min = -32768\n",
      "max = 32767\n",
      "---------------------------------------------------------------\n",
      "\n",
      "Machine parameters for int32\n",
      "---------------------------------------------------------------\n",
      "min = -2147483648\n",
      "max = 2147483647\n",
      "---------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#some examples of datatypes unsigned and signed\n",
    "data_types = [\"uint16\",\"int16\",\"int32\"]\n",
    "for it in data_types:\n",
    "    print(iinfo(it))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the X dataframe we have only int32 types, do we need such datasize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "      <td>30530.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>318.335899</td>\n",
       "      <td>318.282673</td>\n",
       "      <td>318.287717</td>\n",
       "      <td>318.336259</td>\n",
       "      <td>318.341173</td>\n",
       "      <td>318.389781</td>\n",
       "      <td>318.392237</td>\n",
       "      <td>318.366951</td>\n",
       "      <td>318.368588</td>\n",
       "      <td>318.374582</td>\n",
       "      <td>...</td>\n",
       "      <td>318.970259</td>\n",
       "      <td>318.960432</td>\n",
       "      <td>318.986898</td>\n",
       "      <td>319.092368</td>\n",
       "      <td>319.086931</td>\n",
       "      <td>319.192794</td>\n",
       "      <td>319.189584</td>\n",
       "      <td>319.189846</td>\n",
       "      <td>319.168752</td>\n",
       "      <td>319.182607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>605.751158</td>\n",
       "      <td>605.697274</td>\n",
       "      <td>605.695290</td>\n",
       "      <td>605.868836</td>\n",
       "      <td>605.866870</td>\n",
       "      <td>606.040597</td>\n",
       "      <td>606.039463</td>\n",
       "      <td>606.036057</td>\n",
       "      <td>606.036524</td>\n",
       "      <td>606.034319</td>\n",
       "      <td>...</td>\n",
       "      <td>607.320677</td>\n",
       "      <td>607.323330</td>\n",
       "      <td>607.332657</td>\n",
       "      <td>607.558896</td>\n",
       "      <td>607.561000</td>\n",
       "      <td>607.787108</td>\n",
       "      <td>607.788466</td>\n",
       "      <td>607.788331</td>\n",
       "      <td>607.778203</td>\n",
       "      <td>607.784047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.500000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>49.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.750000</td>\n",
       "      <td>299.750000</td>\n",
       "      <td>299.750000</td>\n",
       "      <td>299.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3224.000000</td>\n",
       "      <td>3224.000000</td>\n",
       "      <td>3224.000000</td>\n",
       "      <td>3225.000000</td>\n",
       "      <td>3225.000000</td>\n",
       "      <td>3226.000000</td>\n",
       "      <td>3226.000000</td>\n",
       "      <td>3226.000000</td>\n",
       "      <td>3226.000000</td>\n",
       "      <td>3226.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3231.000000</td>\n",
       "      <td>3231.000000</td>\n",
       "      <td>3231.000000</td>\n",
       "      <td>3232.000000</td>\n",
       "      <td>3232.000000</td>\n",
       "      <td>3233.000000</td>\n",
       "      <td>3233.000000</td>\n",
       "      <td>3233.000000</td>\n",
       "      <td>3233.000000</td>\n",
       "      <td>3233.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0             1             2             3             4   \\\n",
       "count  30530.000000  30530.000000  30530.000000  30530.000000  30530.000000   \n",
       "mean     318.335899    318.282673    318.287717    318.336259    318.341173   \n",
       "std      605.751158    605.697274    605.695290    605.868836    605.866870   \n",
       "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%       10.000000     10.000000     10.000000     10.000000     10.000000   \n",
       "50%       49.000000     49.000000     49.000000     49.000000     49.000000   \n",
       "75%      299.000000    299.000000    299.000000    299.000000    299.000000   \n",
       "max     3224.000000   3224.000000   3224.000000   3225.000000   3225.000000   \n",
       "\n",
       "                 5             6             7             8             9   \\\n",
       "count  30530.000000  30530.000000  30530.000000  30530.000000  30530.000000   \n",
       "mean     318.389781    318.392237    318.366951    318.368588    318.374582   \n",
       "std      606.040597    606.039463    606.036057    606.036524    606.034319   \n",
       "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%       10.000000     10.000000     10.000000     10.000000     10.000000   \n",
       "50%       49.000000     49.500000     49.000000     49.000000     49.500000   \n",
       "75%      299.000000    299.000000    299.000000    299.000000    299.000000   \n",
       "max     3226.000000   3226.000000   3226.000000   3226.000000   3226.000000   \n",
       "\n",
       "           ...                 40            41            42            43  \\\n",
       "count      ...       30530.000000  30530.000000  30530.000000  30530.000000   \n",
       "mean       ...         318.970259    318.960432    318.986898    319.092368   \n",
       "std        ...         607.320677    607.323330    607.332657    607.558896   \n",
       "min        ...           1.000000      1.000000      1.000000      1.000000   \n",
       "25%        ...          10.000000     10.000000     10.000000     10.000000   \n",
       "50%        ...          50.000000     50.000000     50.000000     50.000000   \n",
       "75%        ...         299.000000    299.000000    299.000000    299.000000   \n",
       "max        ...        3231.000000   3231.000000   3231.000000   3232.000000   \n",
       "\n",
       "                 44            45            46            47            48  \\\n",
       "count  30530.000000  30530.000000  30530.000000  30530.000000  30530.000000   \n",
       "mean     319.086931    319.192794    319.189584    319.189846    319.168752   \n",
       "std      607.561000    607.787108    607.788466    607.788331    607.778203   \n",
       "min        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "25%       10.000000     10.000000     10.000000     10.000000     10.000000   \n",
       "50%       50.000000     50.000000     50.000000     50.000000     50.000000   \n",
       "75%      299.000000    299.750000    299.750000    299.750000    299.000000   \n",
       "max     3232.000000   3233.000000   3233.000000   3233.000000   3233.000000   \n",
       "\n",
       "                 49  \n",
       "count  30530.000000  \n",
       "mean     319.182607  \n",
       "std      607.784047  \n",
       "min        1.000000  \n",
       "25%       10.000000  \n",
       "50%       50.000000  \n",
       "75%      299.000000  \n",
       "max     3233.000000  \n",
       "\n",
       "[8 rows x 50 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the values range from 1 to 7317.  Convert the integer types using a simple function to see how much memory we could save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of integer types before 5.82 MB\n",
      "Size of integer types after 2.91 MB\n"
     ]
    }
   ],
   "source": [
    "def mem_usage(pandas_obj):\n",
    "    usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "    usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mb)\n",
    "\n",
    "df1_mem_int = df1.select_dtypes(include=['int32'])\n",
    "converted_int = df1.apply(pd.to_numeric,downcast='unsigned')\n",
    "\n",
    "print(\"Size of integer types before {}\".format(mem_usage(df1_mem_int)))\n",
    "print(\"Size of integer types after {}\".format(mem_usage(converted_int)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Have converted to uint16 which is optimal size for the datatype and saved 50% in space.**\n",
    "\n",
    "Repeat with the float columns of the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of float types before 753.28 MB\n",
      "Size of float types after 94.16 MB\n"
     ]
    }
   ],
   "source": [
    "df2_mem_float = df2.select_dtypes(include=['float64'])\n",
    "converted_float = df2.apply(pd.to_numeric,downcast='unsigned')\n",
    "\n",
    "print(\"Size of float types before {}\".format(mem_usage(df2_mem_float)))\n",
    "print(\"Size of float types after {}\".format(mem_usage(converted_float)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The zeros and ones in the target have been converted into type uint8 saving over 80% in space**\n",
    "\n",
    "Using this information lets convert the original numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original datatype of X array is int32\n",
      "original datatype of y array is float64\n"
     ]
    }
   ],
   "source": [
    "print(\"original datatype of X array is {}\".format(X.dtype))\n",
    "print(\"original datatype of y array is {}\".format(y.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size of 5.823135 MB\n",
      "y size of 753.280792 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"X size of %f MB\" % ((X.size * X.itemsize)/1024**2))\n",
    "print(\"y size of %f MB\" % ((y.size * y.itemsize)/1024**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New X size of 2.911568 MB\n",
      "New y size of 94.160099 MB\n",
      " \n",
      "New datatype of X array is uint16\n",
      "New datatype of y array is uint8\n"
     ]
    }
   ],
   "source": [
    "X_new = X.astype('uint16')\n",
    "y_new = y.astype('uint8')\n",
    "\n",
    "print(\"New X size of %f MB\" % ((X_new.size * X_new.itemsize)/1024**2))\n",
    "print(\"New y size of %f MB\" % ((y_new.size * y_new.itemsize)/1024**2))\n",
    "print(\" \")\n",
    "print(\"New datatype of X array is {}\".format(X_new.dtype))\n",
    "print(\"New datatype of y array is {}\".format(y_new.dtype))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the Model\n",
    "The learned embedding needs to know the size of the vocabulary and the length of input sequences.  It also has a parameter to specify how many dimensions will be used to represent each word - the size of the embedding vector space.\n",
    "Common values are 50, 100, and 300. Use a two LSTM hidden layers with 100 memory cells each. \n",
    "\n",
    "More memory cells and a deeper network may achieve better results. A dense fully connected layer with 100 neurons connects to the LSTM hidden layers to interpret the features extracted from the sequence. The output layer predicts the next word as\n",
    "a single vector the size of the vocabulary with a probability for each word in the vocabulary. A softmax activation function is used to ensure the outputs have the characteristics of normalized probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "def define_model(vocab_size, seq_length):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 50, input_length=seq_length))\n",
    "    model.add(LSTM(100, return_sequences=True))\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(vocab_size, activation='softmax'))\n",
    "    # compile network\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # summarize defined model\n",
    "    model.summary()\n",
    "    plot_model(model, to_file='img/model20.png', show_shapes=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is compiled specifying the categorical cross entropy loss needed to fit the model.\n",
    "Technically, the model is learning a multiclass classification and this is the suitable loss function\n",
    "for this type of problem. The efficient Adam implementation to mini-batch gradient descent\n",
    "is used and accuracy is evaluated of the model. Finally, the model is fit on the data for 100\n",
    "training epochs with a modest batch size of 200 to speed things up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_15 (Embedding)     (None, 50, 50)            161700    \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, 50, 100)           60400     \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 3234)              326634    \n",
      "=================================================================\n",
      "Total params: 639,234\n",
      "Trainable params: 639,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "30530/30530 [==============================] - 21s 692us/step - loss: 6.4659 - acc: 0.0525\n",
      "Epoch 2/50\n",
      "30530/30530 [==============================] - 19s 621us/step - loss: 6.0930 - acc: 0.0558\n",
      "Epoch 3/50\n",
      "30530/30530 [==============================] - 19s 625us/step - loss: 5.9256 - acc: 0.0634\n",
      "Epoch 4/50\n",
      "30530/30530 [==============================] - 20s 643us/step - loss: 5.7655 - acc: 0.0770\n",
      "Epoch 5/50\n",
      "30530/30530 [==============================] - 19s 627us/step - loss: 5.6705 - acc: 0.0892\n",
      "Epoch 6/50\n",
      "30530/30530 [==============================] - 19s 632us/step - loss: 5.6016 - acc: 0.0943\n",
      "Epoch 7/50\n",
      "30530/30530 [==============================] - 19s 632us/step - loss: 5.5343 - acc: 0.1022\n",
      "Epoch 8/50\n",
      "30530/30530 [==============================] - 19s 638us/step - loss: 5.4570 - acc: 0.1100\n",
      "Epoch 9/50\n",
      "30530/30530 [==============================] - 19s 631us/step - loss: 5.3724 - acc: 0.1171\n",
      "Epoch 10/50\n",
      "30530/30530 [==============================] - 19s 635us/step - loss: 5.2899 - acc: 0.1225\n",
      "Epoch 11/50\n",
      "30530/30530 [==============================] - 20s 661us/step - loss: 5.2083 - acc: 0.1306\n",
      "Epoch 12/50\n",
      "30530/30530 [==============================] - 20s 648us/step - loss: 5.1322 - acc: 0.1394\n",
      "Epoch 13/50\n",
      "30530/30530 [==============================] - 19s 632us/step - loss: 5.0692 - acc: 0.1432\n",
      "Epoch 14/50\n",
      "30530/30530 [==============================] - 19s 632us/step - loss: 5.0110 - acc: 0.1462\n",
      "Epoch 15/50\n",
      "30530/30530 [==============================] - 19s 630us/step - loss: 4.9583 - acc: 0.1490\n",
      "Epoch 16/50\n",
      "30530/30530 [==============================] - 19s 628us/step - loss: 4.9117 - acc: 0.1526\n",
      "Epoch 17/50\n",
      "30530/30530 [==============================] - 20s 649us/step - loss: 4.8687 - acc: 0.1538\n",
      "Epoch 18/50\n",
      "30530/30530 [==============================] - 19s 630us/step - loss: 4.8290 - acc: 0.1562\n",
      "Epoch 19/50\n",
      "30530/30530 [==============================] - 19s 629us/step - loss: 4.7910 - acc: 0.1576\n",
      "Epoch 20/50\n",
      "30530/30530 [==============================] - 19s 625us/step - loss: 4.7517 - acc: 0.1588\n",
      "Epoch 21/50\n",
      "30530/30530 [==============================] - 19s 628us/step - loss: 4.7140 - acc: 0.1596\n",
      "Epoch 22/50\n",
      "30530/30530 [==============================] - 19s 628us/step - loss: 4.6789 - acc: 0.1607\n",
      "Epoch 23/50\n",
      "30530/30530 [==============================] - 19s 627us/step - loss: 4.6417 - acc: 0.1614\n",
      "Epoch 24/50\n",
      "30530/30530 [==============================] - 19s 629us/step - loss: 4.6093 - acc: 0.1633\n",
      "Epoch 25/50\n",
      "30530/30530 [==============================] - 19s 628us/step - loss: 4.5755 - acc: 0.1646\n",
      "Epoch 26/50\n",
      "30530/30530 [==============================] - 19s 627us/step - loss: 4.5422 - acc: 0.1659\n",
      "Epoch 27/50\n",
      "30530/30530 [==============================] - 19s 630us/step - loss: 4.5087 - acc: 0.1677\n",
      "Epoch 28/50\n",
      "30530/30530 [==============================] - 20s 644us/step - loss: 4.4753 - acc: 0.1682\n",
      "Epoch 29/50\n",
      "30530/30530 [==============================] - 19s 635us/step - loss: 4.4434 - acc: 0.1699\n",
      "Epoch 30/50\n",
      "30530/30530 [==============================] - 20s 646us/step - loss: 4.4094 - acc: 0.1723\n",
      "Epoch 31/50\n",
      "30530/30530 [==============================] - 19s 628us/step - loss: 4.3786 - acc: 0.1732\n",
      "Epoch 32/50\n",
      "30530/30530 [==============================] - 19s 628us/step - loss: 4.3458 - acc: 0.1730\n",
      "Epoch 33/50\n",
      "30530/30530 [==============================] - 19s 630us/step - loss: 4.3129 - acc: 0.1759\n",
      "Epoch 34/50\n",
      "30530/30530 [==============================] - 19s 629us/step - loss: 4.2798 - acc: 0.1779\n",
      "Epoch 35/50\n",
      "30530/30530 [==============================] - 19s 627us/step - loss: 4.2487 - acc: 0.1779\n",
      "Epoch 36/50\n",
      "30530/30530 [==============================] - 19s 629us/step - loss: 4.2200 - acc: 0.1806\n",
      "Epoch 37/50\n",
      "30530/30530 [==============================] - 19s 634us/step - loss: 4.1903 - acc: 0.1815\n",
      "Epoch 38/50\n",
      "30530/30530 [==============================] - 20s 654us/step - loss: 4.1584 - acc: 0.1837\n",
      "Epoch 39/50\n",
      "30530/30530 [==============================] - 19s 629us/step - loss: 4.1309 - acc: 0.1845\n",
      "Epoch 40/50\n",
      "30530/30530 [==============================] - 20s 652us/step - loss: 4.1025 - acc: 0.1879\n",
      "Epoch 41/50\n",
      "30530/30530 [==============================] - 20s 650us/step - loss: 4.0712 - acc: 0.1887\n",
      "Epoch 42/50\n",
      "30530/30530 [==============================] - 20s 651us/step - loss: 4.0399 - acc: 0.1912\n",
      "Epoch 43/50\n",
      "30530/30530 [==============================] - 19s 632us/step - loss: 4.0120 - acc: 0.1939\n",
      "Epoch 44/50\n",
      "30530/30530 [==============================] - 20s 644us/step - loss: 3.9857 - acc: 0.1954\n",
      "Epoch 45/50\n",
      "30530/30530 [==============================] - 19s 634us/step - loss: 3.9580 - acc: 0.1973\n",
      "Epoch 46/50\n",
      "30530/30530 [==============================] - 19s 635us/step - loss: 3.9270 - acc: 0.1999\n",
      "Epoch 47/50\n",
      "30530/30530 [==============================] - 19s 635us/step - loss: 3.9035 - acc: 0.2021\n",
      "Epoch 48/50\n",
      "30530/30530 [==============================] - 19s 635us/step - loss: 3.8755 - acc: 0.2031\n",
      "Epoch 49/50\n",
      "30530/30530 [==============================] - 19s 627us/step - loss: 3.8474 - acc: 0.2049\n",
      "Epoch 50/50\n",
      "30530/30530 [==============================] - 19s 637us/step - loss: 3.8218 - acc: 0.2096\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = define_model(vocab_size, seq_length)\n",
    "# fit model\n",
    "model.fit(X_new, y_new, batch_size=200, epochs=50)\n",
    "# save the model to file\n",
    "model.save('model20.h5')\n",
    "# save the tokenizer\n",
    "dump(tokenizer, open('tokenizer20.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load cleaned text sequences\n",
    "in_filename = 'the_prince_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "\n",
    "seq_length = len(lines[0].split()) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer20.pkl', 'rb'))\n",
    "model = load_model('model20.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "family or else they are those of recent foundation the newly founded ones are either entirely new as was milan to francesco sforza or else they are as it were new members grafted on to the hereditary possessions of the prince that annexes them as is the kingdom of naples to\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a function called generate seq() that takes as input the model,\n",
    "the tokenizer, input sequence length, the seed text, and the number of words to generate. It\n",
    "then returns a sequence of words generated by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be opposed by those he has about him and he is easily diverted from his purpose hence it comes to pass that what he does one day he undoes the next no one ever understands what he wishes or intends to do and no reliance is to be placed on his\n",
      "\n",
      "own laws and as he had not spent his own laws and as he had not spent his own laws and as he had not spent his own laws and as he had not spent his own laws and as he had not spent his own laws and as he\n"
     ]
    }
   ],
   "source": [
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')\n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
    "print(generated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generated text is not reasonable - this is as expected as the accuracy from the training procedure is very low:\n",
    "- text maybe too small need to increase size \n",
    "- change batch size and epoch number\n",
    "- change the sequence length\n",
    "- change the network configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
