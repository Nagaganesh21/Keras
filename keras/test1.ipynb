{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments on the pima indians dataset\n",
    "- https://archive.ics.uci.edu/ml/datasets/pima+indians+diabetes\n",
    "\n",
    "Attribute information:\n",
    "1. Number of times pregnant \n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. Diastolic blood pressure (mm Hg) \n",
    "4. Triceps skin fold thickness (mm) \n",
    "5. 2-Hour serum insulin (mu U/ml) \n",
    "6. Body mass index (weight in kg/(height in m)^2) \n",
    "7. Diabetes pedigree function \n",
    "8. Age (years) \n",
    "9. Class variable (0 or 1) \n",
    "\n",
    "All numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   V0   V1  V2  V3   V4    V5     V6  V7  V8\n",
      "0   6  148  72  35    0  33.6  0.627  50   1\n",
      "1   1   85  66  29    0  26.6  0.351  31   0\n",
      "2   8  183  64   0    0  23.3  0.672  32   1\n",
      "3   1   89  66  23   94  28.1  0.167  21   0\n",
      "4   0  137  40  35  168  43.1  2.288  33   1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(7)\n",
    "\n",
    "#get the data \n",
    "url = (\"http://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\")\n",
    "dataset = pd.read_csv(url, header=None, prefix='V')\n",
    "\n",
    "#print summary info\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   6.     148.      72.      35.       0.      33.6      0.627   50.   ] 1\n"
     ]
    }
   ],
   "source": [
    "#seperate data into input and output variables\n",
    "X = np.array(dataset.iloc[:, 0:8])\n",
    "Y = np.array(dataset.iloc[:, 8])\n",
    "#check first row of data\n",
    "print(X[0],Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model\n",
    "Try using relu activation function on the first two layers and the sigmoid \n",
    "activation function in the output layer. Use a sigmoid activation function on the output layer\n",
    "to ensure network output is between 0 and 1 and easy to map to either a probability of class 1 or snap to a hard \n",
    "classification of either class with a default threshold of 0.5. The first hidden layer has 12 neurons and expects\n",
    "8 input variables (e.g. input dim=8).  The second hidden layer has 8 neurons and finally the output layer\n",
    "has 1 neuron to predict the class (onset of diabetes or not)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "model = Sequential()    #linear stack of layers\n",
    "model.add(Dense(12,input_dim=8,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model\n",
    "Using tensorflow backend\n",
    "Using log loss as cost function and binary use keras binary_crossentropy - http://wiki.fast.ai/index.php/Log_Loss\n",
    "\n",
    "Gradient descent algorithm use Adam - http://ruder.io/optimizing-gradient-descent/index.html\n",
    "\n",
    "Classifcation problem collect and report the classification accuracy as the metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#compile the model\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the model\n",
    "Run for a fixed number of iterations through the dataset (epochs).  Set the number of instances that are evaluated beforea weight update in the network is performed (batch size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "768/768 [==============================] - 1s 749us/step - loss: 3.7794 - acc: 0.5977\n",
      "Epoch 2/150\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.9836 - acc: 0.5742\n",
      "Epoch 3/150\n",
      "768/768 [==============================] - 0s 297us/step - loss: 0.7513 - acc: 0.6406\n",
      "Epoch 4/150\n",
      "768/768 [==============================] - 0s 299us/step - loss: 0.7163 - acc: 0.6510\n",
      "Epoch 5/150\n",
      "768/768 [==============================] - 0s 304us/step - loss: 0.6999 - acc: 0.6628\n",
      "Epoch 6/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.6822 - acc: 0.6693\n",
      "Epoch 7/150\n",
      "768/768 [==============================] - 0s 315us/step - loss: 0.6592 - acc: 0.6784\n",
      "Epoch 8/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.6542 - acc: 0.6719\n",
      "Epoch 9/150\n",
      "768/768 [==============================] - 0s 298us/step - loss: 0.6468 - acc: 0.6615\n",
      "Epoch 10/150\n",
      "768/768 [==============================] - 0s 309us/step - loss: 0.6438 - acc: 0.6914\n",
      "Epoch 11/150\n",
      "768/768 [==============================] - 0s 313us/step - loss: 0.6285 - acc: 0.6966\n",
      "Epoch 12/150\n",
      "768/768 [==============================] - 0s 303us/step - loss: 0.6138 - acc: 0.6888\n",
      "Epoch 13/150\n",
      "768/768 [==============================] - 0s 303us/step - loss: 0.6208 - acc: 0.6810\n",
      "Epoch 14/150\n",
      "768/768 [==============================] - 0s 323us/step - loss: 0.6467 - acc: 0.6979\n",
      "Epoch 15/150\n",
      "768/768 [==============================] - 0s 311us/step - loss: 0.6289 - acc: 0.6953\n",
      "Epoch 16/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.6110 - acc: 0.6979\n",
      "Epoch 17/150\n",
      "768/768 [==============================] - 0s 307us/step - loss: 0.5907 - acc: 0.7096\n",
      "Epoch 18/150\n",
      "768/768 [==============================] - 0s 335us/step - loss: 0.5842 - acc: 0.7122\n",
      "Epoch 19/150\n",
      "768/768 [==============================] - 0s 320us/step - loss: 0.5899 - acc: 0.7109\n",
      "Epoch 20/150\n",
      "768/768 [==============================] - 0s 306us/step - loss: 0.6040 - acc: 0.6901\n",
      "Epoch 21/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.5976 - acc: 0.7031\n",
      "Epoch 22/150\n",
      "768/768 [==============================] - 0s 309us/step - loss: 0.5801 - acc: 0.7201\n",
      "Epoch 23/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.5774 - acc: 0.7109\n",
      "Epoch 24/150\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.5978 - acc: 0.7122\n",
      "Epoch 25/150\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.5630 - acc: 0.7266\n",
      "Epoch 26/150\n",
      "768/768 [==============================] - 0s 307us/step - loss: 0.5649 - acc: 0.7148\n",
      "Epoch 27/150\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.5615 - acc: 0.7161\n",
      "Epoch 28/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.5749 - acc: 0.6992\n",
      "Epoch 29/150\n",
      "768/768 [==============================] - 0s 299us/step - loss: 0.5642 - acc: 0.7227\n",
      "Epoch 30/150\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.5502 - acc: 0.7318\n",
      "Epoch 31/150\n",
      "768/768 [==============================] - 0s 304us/step - loss: 0.5552 - acc: 0.7396\n",
      "Epoch 32/150\n",
      "768/768 [==============================] - 0s 301us/step - loss: 0.5570 - acc: 0.7201\n",
      "Epoch 33/150\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.5595 - acc: 0.7135\n",
      "Epoch 34/150\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.5519 - acc: 0.7161\n",
      "Epoch 35/150\n",
      "768/768 [==============================] - 0s 304us/step - loss: 0.5484 - acc: 0.7227\n",
      "Epoch 36/150\n",
      "768/768 [==============================] - ETA: 0s - loss: 0.5517 - acc: 0.726 - 0s 332us/step - loss: 0.5498 - acc: 0.7292\n",
      "Epoch 37/150\n",
      "768/768 [==============================] - 0s 354us/step - loss: 0.5363 - acc: 0.7422\n",
      "Epoch 38/150\n",
      "768/768 [==============================] - 0s 397us/step - loss: 0.5384 - acc: 0.7279\n",
      "Epoch 39/150\n",
      "768/768 [==============================] - 0s 348us/step - loss: 0.5676 - acc: 0.7005\n",
      "Epoch 40/150\n",
      "768/768 [==============================] - 0s 340us/step - loss: 0.5336 - acc: 0.7422\n",
      "Epoch 41/150\n",
      "768/768 [==============================] - 0s 310us/step - loss: 0.5546 - acc: 0.7201\n",
      "Epoch 42/150\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.5497 - acc: 0.7370\n",
      "Epoch 43/150\n",
      "768/768 [==============================] - 0s 292us/step - loss: 0.5406 - acc: 0.7344\n",
      "Epoch 44/150\n",
      "768/768 [==============================] - 0s 309us/step - loss: 0.5328 - acc: 0.7409\n",
      "Epoch 45/150\n",
      "768/768 [==============================] - 0s 317us/step - loss: 0.5426 - acc: 0.7279\n",
      "Epoch 46/150\n",
      "768/768 [==============================] - 0s 335us/step - loss: 0.5273 - acc: 0.7565\n",
      "Epoch 47/150\n",
      "768/768 [==============================] - 0s 358us/step - loss: 0.5238 - acc: 0.7604\n",
      "Epoch 48/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.5914 - acc: 0.7122\n",
      "Epoch 49/150\n",
      "768/768 [==============================] - 0s 317us/step - loss: 0.5616 - acc: 0.7214\n",
      "Epoch 50/150\n",
      "768/768 [==============================] - 0s 323us/step - loss: 0.5222 - acc: 0.7630\n",
      "Epoch 51/150\n",
      "768/768 [==============================] - 0s 287us/step - loss: 0.5284 - acc: 0.7331\n",
      "Epoch 52/150\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.5330 - acc: 0.7435\n",
      "Epoch 53/150\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.5230 - acc: 0.7500\n",
      "Epoch 54/150\n",
      "768/768 [==============================] - 0s 263us/step - loss: 0.5238 - acc: 0.7539\n",
      "Epoch 55/150\n",
      "768/768 [==============================] - 0s 279us/step - loss: 0.5262 - acc: 0.7513\n",
      "Epoch 56/150\n",
      "768/768 [==============================] - 0s 309us/step - loss: 0.5293 - acc: 0.7344\n",
      "Epoch 57/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.5427 - acc: 0.7357\n",
      "Epoch 58/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.5250 - acc: 0.7318\n",
      "Epoch 59/150\n",
      "768/768 [==============================] - 0s 308us/step - loss: 0.5295 - acc: 0.7461\n",
      "Epoch 60/150\n",
      "768/768 [==============================] - 0s 323us/step - loss: 0.5238 - acc: 0.7461\n",
      "Epoch 61/150\n",
      "768/768 [==============================] - 0s 345us/step - loss: 0.5281 - acc: 0.7357\n",
      "Epoch 62/150\n",
      "768/768 [==============================] - 0s 318us/step - loss: 0.5143 - acc: 0.7513\n",
      "Epoch 63/150\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.5384 - acc: 0.7409\n",
      "Epoch 64/150\n",
      "768/768 [==============================] - 0s 317us/step - loss: 0.5195 - acc: 0.7383\n",
      "Epoch 65/150\n",
      "768/768 [==============================] - 0s 318us/step - loss: 0.5263 - acc: 0.7331\n",
      "Epoch 66/150\n",
      "768/768 [==============================] - 0s 310us/step - loss: 0.5062 - acc: 0.7591\n",
      "Epoch 67/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.5256 - acc: 0.7448\n",
      "Epoch 68/150\n",
      "768/768 [==============================] - 0s 299us/step - loss: 0.5059 - acc: 0.7591\n",
      "Epoch 69/150\n",
      "768/768 [==============================] - 0s 311us/step - loss: 0.5126 - acc: 0.7565\n",
      "Epoch 70/150\n",
      "768/768 [==============================] - 0s 304us/step - loss: 0.5206 - acc: 0.7448\n",
      "Epoch 71/150\n",
      "768/768 [==============================] - 0s 320us/step - loss: 0.5106 - acc: 0.7526\n",
      "Epoch 72/150\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.5183 - acc: 0.7435\n",
      "Epoch 73/150\n",
      "768/768 [==============================] - 0s 356us/step - loss: 0.5122 - acc: 0.7383\n",
      "Epoch 74/150\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.5243 - acc: 0.7292\n",
      "Epoch 75/150\n",
      "768/768 [==============================] - 0s 323us/step - loss: 0.5162 - acc: 0.7305\n",
      "Epoch 76/150\n",
      "768/768 [==============================] - 0s 312us/step - loss: 0.5024 - acc: 0.7708\n",
      "Epoch 77/150\n",
      "768/768 [==============================] - 0s 313us/step - loss: 0.5046 - acc: 0.7656\n",
      "Epoch 78/150\n",
      "768/768 [==============================] - 0s 315us/step - loss: 0.5208 - acc: 0.7461\n",
      "Epoch 79/150\n",
      "768/768 [==============================] - 0s 326us/step - loss: 0.5003 - acc: 0.7565\n",
      "Epoch 80/150\n",
      "768/768 [==============================] - 0s 277us/step - loss: 0.5041 - acc: 0.7643\n",
      "Epoch 81/150\n",
      "768/768 [==============================] - 0s 286us/step - loss: 0.4960 - acc: 0.7786\n",
      "Epoch 82/150\n",
      "768/768 [==============================] - 0s 325us/step - loss: 0.4993 - acc: 0.7565\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 304us/step - loss: 0.5083 - acc: 0.7461\n",
      "Epoch 84/150\n",
      "768/768 [==============================] - 0s 292us/step - loss: 0.5130 - acc: 0.7565\n",
      "Epoch 85/150\n",
      "768/768 [==============================] - 0s 323us/step - loss: 0.5077 - acc: 0.7578\n",
      "Epoch 86/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.5102 - acc: 0.7422\n",
      "Epoch 87/150\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.4967 - acc: 0.7708\n",
      "Epoch 88/150\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.4929 - acc: 0.7630\n",
      "Epoch 89/150\n",
      "768/768 [==============================] - 0s 314us/step - loss: 0.4980 - acc: 0.7604\n",
      "Epoch 90/150\n",
      "768/768 [==============================] - 0s 294us/step - loss: 0.5036 - acc: 0.7552\n",
      "Epoch 91/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.5051 - acc: 0.7591\n",
      "Epoch 92/150\n",
      "768/768 [==============================] - 0s 278us/step - loss: 0.5020 - acc: 0.7760\n",
      "Epoch 93/150\n",
      "768/768 [==============================] - 0s 295us/step - loss: 0.4924 - acc: 0.7643\n",
      "Epoch 94/150\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.4997 - acc: 0.7669\n",
      "Epoch 95/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.4854 - acc: 0.7760\n",
      "Epoch 96/150\n",
      "768/768 [==============================] - 0s 300us/step - loss: 0.4848 - acc: 0.7786\n",
      "Epoch 97/150\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.4989 - acc: 0.7578\n",
      "Epoch 98/150\n",
      "768/768 [==============================] - 0s 305us/step - loss: 0.4841 - acc: 0.7760\n",
      "Epoch 99/150\n",
      "768/768 [==============================] - 0s 303us/step - loss: 0.4861 - acc: 0.7617\n",
      "Epoch 100/150\n",
      "768/768 [==============================] - 0s 290us/step - loss: 0.4876 - acc: 0.7630\n",
      "Epoch 101/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.5273 - acc: 0.7409\n",
      "Epoch 102/150\n",
      "768/768 [==============================] - 0s 294us/step - loss: 0.4834 - acc: 0.7734\n",
      "Epoch 103/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.4858 - acc: 0.7643\n",
      "Epoch 104/150\n",
      "768/768 [==============================] - 0s 303us/step - loss: 0.4836 - acc: 0.7708\n",
      "Epoch 105/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.4867 - acc: 0.7682\n",
      "Epoch 106/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.4837 - acc: 0.7643\n",
      "Epoch 107/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.4942 - acc: 0.7526\n",
      "Epoch 108/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.4811 - acc: 0.7721\n",
      "Epoch 109/150\n",
      "768/768 [==============================] - 0s 289us/step - loss: 0.4826 - acc: 0.7734\n",
      "Epoch 110/150\n",
      "768/768 [==============================] - 0s 294us/step - loss: 0.4781 - acc: 0.7799\n",
      "Epoch 111/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.4933 - acc: 0.7708\n",
      "Epoch 112/150\n",
      "768/768 [==============================] - 0s 292us/step - loss: 0.4811 - acc: 0.7695\n",
      "Epoch 113/150\n",
      "768/768 [==============================] - 0s 292us/step - loss: 0.4813 - acc: 0.7786\n",
      "Epoch 114/150\n",
      "768/768 [==============================] - 0s 292us/step - loss: 0.4822 - acc: 0.7695\n",
      "Epoch 115/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.4749 - acc: 0.7708\n",
      "Epoch 116/150\n",
      "768/768 [==============================] - 0s 292us/step - loss: 0.4806 - acc: 0.7695\n",
      "Epoch 117/150\n",
      "768/768 [==============================] - 0s 296us/step - loss: 0.4891 - acc: 0.7747\n",
      "Epoch 118/150\n",
      "768/768 [==============================] - 0s 294us/step - loss: 0.4705 - acc: 0.7786\n",
      "Epoch 119/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.4897 - acc: 0.7682\n",
      "Epoch 120/150\n",
      "768/768 [==============================] - 0s 321us/step - loss: 0.4935 - acc: 0.7552\n",
      "Epoch 121/150\n",
      "768/768 [==============================] - 0s 309us/step - loss: 0.4796 - acc: 0.7812\n",
      "Epoch 122/150\n",
      "768/768 [==============================] - 0s 314us/step - loss: 0.4799 - acc: 0.7682\n",
      "Epoch 123/150\n",
      "768/768 [==============================] - 0s 343us/step - loss: 0.4782 - acc: 0.7773\n",
      "Epoch 124/150\n",
      "768/768 [==============================] - 0s 343us/step - loss: 0.4768 - acc: 0.7708\n",
      "Epoch 125/150\n",
      "768/768 [==============================] - 0s 288us/step - loss: 0.4769 - acc: 0.7721\n",
      "Epoch 126/150\n",
      "768/768 [==============================] - 0s 314us/step - loss: 0.4777 - acc: 0.7734\n",
      "Epoch 127/150\n",
      "768/768 [==============================] - 0s 342us/step - loss: 0.4819 - acc: 0.7786\n",
      "Epoch 128/150\n",
      "768/768 [==============================] - 0s 315us/step - loss: 0.4826 - acc: 0.7760\n",
      "Epoch 129/150\n",
      "768/768 [==============================] - 0s 313us/step - loss: 0.4744 - acc: 0.7747\n",
      "Epoch 130/150\n",
      "768/768 [==============================] - 0s 310us/step - loss: 0.4808 - acc: 0.7682\n",
      "Epoch 131/150\n",
      "768/768 [==============================] - 0s 316us/step - loss: 0.4720 - acc: 0.7695\n",
      "Epoch 132/150\n",
      "768/768 [==============================] - 0s 291us/step - loss: 0.4744 - acc: 0.7760\n",
      "Epoch 133/150\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.4659 - acc: 0.7656\n",
      "Epoch 134/150\n",
      "768/768 [==============================] - 0s 327us/step - loss: 0.4791 - acc: 0.7708\n",
      "Epoch 135/150\n",
      "768/768 [==============================] - 0s 318us/step - loss: 0.4754 - acc: 0.7734\n",
      "Epoch 136/150\n",
      "768/768 [==============================] - 0s 320us/step - loss: 0.4762 - acc: 0.7747\n",
      "Epoch 137/150\n",
      "768/768 [==============================] - 0s 271us/step - loss: 0.4690 - acc: 0.7695\n",
      "Epoch 138/150\n",
      "768/768 [==============================] - 0s 320us/step - loss: 0.4760 - acc: 0.7747\n",
      "Epoch 139/150\n",
      "768/768 [==============================] - 0s 302us/step - loss: 0.4814 - acc: 0.7669\n",
      "Epoch 140/150\n",
      "768/768 [==============================] - 0s 285us/step - loss: 0.4805 - acc: 0.7708\n",
      "Epoch 141/150\n",
      "768/768 [==============================] - 0s 328us/step - loss: 0.4803 - acc: 0.7734\n",
      "Epoch 142/150\n",
      "768/768 [==============================] - 0s 331us/step - loss: 0.4764 - acc: 0.7734\n",
      "Epoch 143/150\n",
      "768/768 [==============================] - 0s 315us/step - loss: 0.4670 - acc: 0.7747\n",
      "Epoch 144/150\n",
      "768/768 [==============================] - 0s 279us/step - loss: 0.4658 - acc: 0.7695\n",
      "Epoch 145/150\n",
      "768/768 [==============================] - 0s 279us/step - loss: 0.4631 - acc: 0.7904\n",
      "Epoch 146/150\n",
      "768/768 [==============================] - 0s 293us/step - loss: 0.4864 - acc: 0.7721\n",
      "Epoch 147/150\n",
      "768/768 [==============================] - 0s 281us/step - loss: 0.4728 - acc: 0.7799\n",
      "Epoch 148/150\n",
      "768/768 [==============================] - 0s 317us/step - loss: 0.4689 - acc: 0.7812\n",
      "Epoch 149/150\n",
      "768/768 [==============================] - 0s 307us/step - loss: 0.4697 - acc: 0.7708\n",
      "Epoch 150/150\n",
      "768/768 [==============================] - 0s 313us/step - loss: 0.4660 - acc: 0.7734\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1212158d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y,epochs=150,batch_size=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Model\n",
    "Simple evaluation no seperation of train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 26us/step\n",
      "\n",
      "acc: 78.52%\n"
     ]
    }
   ],
   "source": [
    "#evaluate the model\n",
    "scores = model.evaluate(X,Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45057300850749016, 0.78515625] acc\n"
     ]
    }
   ],
   "source": [
    "print(scores,model.metrics_names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
