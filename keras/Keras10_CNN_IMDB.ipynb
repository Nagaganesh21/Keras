{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Sentiment From Movie Reviews\n",
    "- IMDB sentiment analysis problem for natural language processing\n",
    "- Use word embedding in Keras for natural language problems.\n",
    "- Develop and evaluate a Multilayer Perceptron model for the IMDB problem.\n",
    "- Develop a one-dimensional convolutional neural network model for the IMDBproblem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data\n",
    "(X_train,y_train),(X_test,y_test) = imdb.load_data()\n",
    "X = np.concatenate((X_train, X_test),axis =0)\n",
    "y = np.concatenate((y_train, y_test),axis =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "#get the data shape\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "#what are class values\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary classification problem - good and bad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88585\n"
     ]
    }
   ],
   "source": [
    "#get the number of words\n",
    "print(len(np.unique(np.hstack(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234.75892"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = map(len,X)\n",
    "result = list(result)\n",
    "np.mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean 234.76 words (172.911495)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#get the average review length and std\n",
    "result = list(map(len,X))\n",
    "print(\"Mean %.2f words (%f)\" % (np.mean((result)), np.std((result))))\n",
    "# plot review length as a boxplot and histogram\n",
    "plt.subplot(121)\n",
    "plt.boxplot(result)\n",
    "plt.subplot(122)\n",
    "plt.hist(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From box and whisker plot see exponential distribution, mass probably in length 400-500 words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embeddings in Keras\n",
    "Word embedding - where words are encoded as real-valued vectors in a high dimensional space, where\n",
    "the similarity between words in terms of meaning translates to closeness in the vector space.\n",
    "Discrete words are mapped to vectors of continuous numbers. This is useful when working with\n",
    "natural language problems with neural networks as we require numbers as input values.\n",
    "\n",
    "In Keras convert positive integer representations of words into a\n",
    "word embedding by an **Embedding** layer4.  The layer takes arguments that define the mapping\n",
    "including the maximum number of expected words also called the vocabulary size.  The layer also allows you to specify the\n",
    "dimensionality for each word vector, called the output dimension.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine only required fist 5000 words in IMDB dataset, use a 32-dimensional vector to represent each word.Also cap max length of review to 500 words.  Use Keras utils to set datset to length of 500 words.  Then first layer of CNN would be a word embedded layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.embeddings.Embedding at 0x1ecdb47f828>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.load_data(num_words=5000)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=500)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=500)\n",
    "Embedding(5000, 32, input_length=500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Multilayer Perceptron Model\n",
    "Develop a simple Multilayer Perceptron Model with a single hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP for the IMDB problem\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "#truncate a 500 words (shorter reviews zero padded)\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use an Embedding layer as the input layer, setting\n",
    "the vocabulary to 5,000, the word vector size to 32 dimensions and the input length to 500.\n",
    "The output of this first layer will be a 32 Ã— 500 sized matrix as above.\n",
    "Flatten the Embedding layers output to one dimension, then use one dense hidden layer\n",
    "of 250 units with a rectifier activation function. The output layer has one neuron and will use a\n",
    "sigmoid activation to output values of 0 and 1 as predictions. The model uses logarithmic loss\n",
    "and is optimized using the efficient ADAM optimization procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               4000250   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 4,160,501\n",
      "Trainable params: 4,160,501\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 6s 230us/step - loss: 0.5106 - acc: 0.7108 - val_loss: 0.3267 - val_acc: 0.8571\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 3s 126us/step - loss: 0.1908 - acc: 0.9272 - val_loss: 0.3006 - val_acc: 0.8731\n",
      "Accuracy: 87.31%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model - try some different settings\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128, verbose=1)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Dimensional Convolutional Neural Network\n",
    "\n",
    "Convolutional neural networks were designed to honor the spatial structure in image data whilst\n",
    "being robust to the position and orientation of learned objects in the scene. This same principle\n",
    "can be used on sequences, such as the one-dimensional sequence of words in a movie review.\n",
    "The same properties that make the CNN model attractive for learning to recognize objects in\n",
    "images can help to learn structure in paragraphs of words, namely the techniques invariance to\n",
    "the specific position of features.\n",
    "Keras supports one dimensional convolutions and pooling by the Conv1D and MaxPooling1D\n",
    "classes respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN for the IMDB problem\n",
    "import numpy as np\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "# pad dataset to a maximum review length in words\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead now after Embedding input layer, insert a **Conv1D** layer.  This convolutional layer has 32 feature maps and reads\n",
    "embedded word representations 3 vector elements of the word embedding at a time. The\n",
    "convolutional layer is followed by a MaxPooling1D layer with a length and stride of 2 that halves\n",
    "the size of the feature maps from the convolutional layer. The rest of the network is the same\n",
    "as the neural network above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 250, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 250)               2000250   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 251       \n",
      "=================================================================\n",
      "Total params: 2,163,605\n",
      "Trainable params: 2,163,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, 32, input_length=max_words))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional layer preserves the dimensionality of our Embedding\n",
    "input layer of 32 dimensional input with a maximum of 500 words. The pooling layer compresses\n",
    "this representation by halving it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      " - 5s - loss: 0.4694 - acc: 0.7394 - val_loss: 0.2778 - val_acc: 0.8841\n",
      "Epoch 2/2\n",
      " - 4s - loss: 0.2194 - acc: 0.9141 - val_loss: 0.2751 - val_acc: 0.8852\n",
      "Accuracy: 88.52%\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=2, batch_size=128,verbose=2)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Small improvement in accuracy but also faster - less params used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
